{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделяющие границы классов\n",
    "![](http://scikit-learn.org/stable/_images/sphx_glr_plot_classifier_comparison_001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решающие списки\n",
    "![](img/decision_list.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Деревья принятия решений\n",
    "\n",
    "Зачастую дерево решений служит обобщением опыта экспертов, средством передачи знаний будущим сотрудникам или моделью бизнес-процесса компании. Например, до внедрения масштабируемых алгоритмов машинного обучения в банковской сфере задача кредитного скоринга решалась экспертами. Решение о выдаче кредита заемщику принималось на основе некоторых интуитивно (или по опыту) выведенных правил, которые можно представить в виде дерева решений.\n",
    "![](https://habrastorage.org/files/194/9b6/ae9/1949b6ae97ab4fc9b1a37fbf182eda8f.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавление правил. Критерий информативности\n",
    "\n",
    "**Очевидный** - p-n\n",
    "\n",
    "**Энтропийный критерий** - $S = -\\Sigma_{i=1}^Np_ilog_2p_i$\n",
    "\n",
    "**Критерий Джини** - $Gini = -\\Sigma_{i=1}^Np_i(1 - p_i)$\n",
    "\n",
    "**Критерий бустинга** - $\\sqrt{p} - \\sqrt{n}$\n",
    "\n",
    "**Нормированный критерий бустинга** - $\\sqrt{{p}\\over{P}} - \\sqrt{{n}\\over{N}}$\n",
    "\n",
    "**Дисперсия** (для регрессии) - $D = {{1}\\over{l}}\\Sigma_{i=1}^l(y_i-{{1}\\over{l}}\\Sigma_{i=1}^ly_i)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Энтропия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для иллюстрации того, как энтропия поможет определить хорошие признаки для построения дерева, приведем тот же игрушечный пример, что в статье [Энтропия и деревья принятия решений](https://habrahabr.ru/post/171759/). Будем предсказывать цвет шарика по его координате. Конечно, ничего общего с жизнью это не имеет, но позволяет показать, как энтропия используется для построения дерева решений.\n",
    "![](https://habrastorage.org/files/c96/80a/a4b/c9680aa4babc40f4bbc8b3595e203979.png)\n",
    "Здесь 9 синих шариков и 11 желтых. Если мы наудачу вытащили шарик, то он с вероятностью $p_1={9}\\over{20}$ будет синим и с вероятностью $p_2={11}\\over{20}$ – желтым. Значит, энтропия состояния $S_0=−{{9}\\over{20}}log_2{⁡{9}\\over{20}}−{{11}\\over{20}}log_2{⁡{11}\\over{20}}\\approx1$. Само это значение пока ни о чем нам не говорит. Теперь посмотрим, как изменится энтропия, если разбить шарики на две группы – с координатой меньше либо равной 12 и больше 12.\n",
    "![](https://habrastorage.org/files/186/444/a8b/186444a8bd0e451c8324ca8529f8d4f4.png)\n",
    "В левой группе оказалось 13 шаров, из которых 8 синих и 5 желтых. Энтропия этой группы равна $S_1=−{{5}\\over{13}}log_2{{⁡5}\\over{13}}−{{8}\\over{13}}log_2⁡{{8}\\over{13}}\\approx0.96$. В правой группе оказалось 7 шаров, из которых 1 синий и 6 желтых. Энтропия правой группы равна $S_2=−{{1}\\over{7}}log_2⁡{{1}\\over{7}}−{{6}\\over{7}}log_2{{⁡6}\\over{7}}\\approx0.6$. Как видим, энтропия уменьшилась в обеих группах по сравнению с начальным состоянием, хоть в левой и не сильно. Поскольку энтропия – по сути степень хаоса (или неопределенности) в системе, уменьшение энтропии называют приростом информации. Формально прирост информации (information gain, IG) при разбиении выборки по признаку Q (в нашем примере это признак \"x≤12\") определяется как\n",
    "$$IG(Q)=S_0-\\Sigma_{i=1}^q{{N_i}\\over{N}}S_i$$\n",
    "где $q$ – число групп после разбиения, $N_i$ – число элементов выборки, у которых признак Q имеет i-ое значение. В нашем случае после разделения получилось две группы (q=2) – одна из 13 элементов ($N_1=13$), вторая – из 7 ($N_2=7$). Прирост информации получился\n",
    "$$IG(x\\leq12) = S_0 - {{13}\\over{20}}S_1 - {{7}\\over{20}}S_2 \\approx 0.16$$\n",
    "Получается, разделив шарики на две группы по признаку \"координата меньше либо равна 12\", мы уже получили более упорядоченную систему, чем в начале. Продолжим деление шариков на группы до тех пор, пока в каждой группе шарики не будут одного цвета.\n",
    "![](https://habrastorage.org/files/dae/a88/2b0/daea882b0a8e4ef4b23325c88f0353a1.png)\n",
    "Для правой группы потребовалось всего одно дополнительное разбиение по признаку \"координата меньше либо равна 18\", для левой – еще три. Очевидно, энтропия группы с шариками одного цвета равна 0 $(log_2⁡1=0)$, что соответствует представлению, что группа шариков одного цвета – упорядоченная.\n",
    "В итоге мы построили дерево решений, предсказывающее цвет шарика по его координате. Отметим, что такое дерево решений может плохо работать для новых объектов (определения цвета новых шариков), поскольку оно идеально подстроилось под обучающую выборку (изначальные 20 шариков). Для классификации новых шариков лучше подойдет дерево с меньшим числом \"вопросов\", или разделений, пусть даже оно и не идеально разбивает по цветам обучающую выборку. Эту проблему, переобучение, мы еще рассмотрим далее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример 1 (Классификация)\n",
    "Предположим, мы решаем задачу бинарной классификации. Как будет выглядеть решение для линейного классификатора?\n",
    "![](https://habrastorage.org/files/987/707/6e8/9877076e87ac410b8e40eedc77a17a99.png)\n",
    "Как будет выглядеть граница для дерева?\n",
    "![](https://habrastorage.org/files/560/d97/0ca/560d970caaf749fda34bd8417160ed7e.png)\n",
    "Как будет выглядеть само дерево?\n",
    "![](https://habrastorage.org/files/bf1/1fe/490/bf11fe49088f428996a27b0d2d2a6592.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример 2 (регрессия)\n",
    "![](https://habrastorage.org/files/856/c8b/9ad/856c8b9ad9094250a9d23e91e6f74e97.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Готовые реализации\n",
    "[sklearn.tree.DecisionTreeClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "\n",
    "**Параметры:**\n",
    "* *max_depth* – максимальная глубина дерева\n",
    "* *max_features* — максимальное число признаков, по которым ищется лучшее разбиение в дереве (это нужно потому, что при большом количестве признаков будет \"дорого\" искать лучшее (по критерию типа прироста информации) разбиение среди всех признаков)\n",
    "* *min_samples_leaf* – минимальное число объектов в листе. У этого параметра есть понятная интерпретация: скажем, если он равен 5, то дерево будет порождать только те классифицирующие правила, которые верны как минимум для 5 объектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практика\n",
    "**Задание:** Используя [данные](https://raw.githubusercontent.com/gastonstat/CreditScoring/master/CreditScoring.csv) о кредитных займах, обучите DecisionTreeClassifier с наилучшими на Ваш вглзяд параметрами. Сравните полученное качество с результатами прошлого домашнего задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\artem\\anaconda3\\envs\\wos\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # фильтр красных предупреждений\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/gastonstat/CreditScoring/master/CreditScoring.csv') # прочитаем данные\n",
    "data = data[data['Status'] > 0] # выкинем объекты с нулевым кредитным статусом\n",
    "X, y = data.drop('Status', 1), data['Status'] # качестве объёктов-признаков возьмём всё кроме статуса заёмщика. Последний возьмём в качестве целевой переменной\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "params_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': list(range(5, 10)),\n",
    "    'max_features': [0.1, 0.2, 0.3, 0.5, 0.7, 0.9, 1.0],\n",
    "    'min_samples_leaf': list(range(3, 20))\n",
    "}\n",
    "gs = GridSearchCV(clf, params_grid, scoring='accuracy')\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "clf = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree accuracy: 78.45%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Logistic regression accuracy: 78.45%\n",
    "# SVM accuracy: 79.24%\n",
    "print('Decision tree accuracy: %.2f%%' % (100 * accuracy_score(clf.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Экспорт графа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установим библиотеки для рендеринга деревьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\artem\\anaconda3\\envs\\wos\\lib\\site-packages\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\artem\\anaconda3\\envs\\wos\\lib\\site-packages (from pydot)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\artem\\anaconda3\\envs\\wos\\lib\\site-packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Экспортируем дерево в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(clf, out_file='img/tree.dot', filled=True, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее скопируйте содержимое этого файла [сюда](http://webgraphviz.com) и получите картинку с полученным Вами деревом. Согласуется ли такая логика дерева с Вашими ожиданиями?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Полезные ссылки\n",
    "* [Ещё раз про деревья, KNN и кросс-валидацию](https://habrahabr.ru/company/ods/blog/322534/)\n",
    "* [Энтропия и деревья принятия решений](https://habrahabr.ru/post/171759/)\n",
    "* [Видеолекция Воронцова](https://www.youtube.com/watch?v=qk-9KHobGHA&list=PLJOzdkh8T5kp99tGTEFjH_b9zqEQiiBtC&index=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
